{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Machine Translation Experiments for Hindi-English using an Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "F:\\Installed\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Installed\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Installed\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Installed\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Installed\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Installed\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import re\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127607, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data\n",
    "data = pd.read_csv(\"hi_en_corpus.csv\", encoding='utf-8')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0        ted  politicians do not have permission to do what ...   \n",
       "1        ted         I'd like to tell you about one such child,   \n",
       "2  indic2012  This percentage is even greater than the perce...   \n",
       "3        ted  what we really mean is that they're bad at not...   \n",
       "4  indic2012  .The ending portion of these Vedas is called U...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    0\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['source']=='ted']\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38803, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly sampling 25000 sentences from the data for training\n",
    "data = data.sample(n=25000,random_state=42)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all characters\n",
    "data['english_sentence'] = data['english_sentence'].apply(lambda x: x.lower())\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "data['english_sentence'] = data['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the special characters\n",
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "data['english_sentence'] = data['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "data['english_sentence'] = data['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "data['english_sentence'] = data['english_sentence'].apply(lambda x: x.strip())\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: x.strip())\n",
    "data['english_sentence'] = data['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target sequences\n",
    "data['hindi_sentence'] = data['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate cli...</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "82040     ted  we still dont know who her parents are who she is   \n",
       "85038     ted                                        no keyboard   \n",
       "58018     ted                    but as far as being a performer   \n",
       "74470     ted                        and this particular balloon   \n",
       "122330    ted  and its not as hard as you think integrate cli...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...  \n",
       "85038                       START_ कोई कुंजीपटल नहीं _END  \n",
       "58018             START_ लेकिन एक कलाकार होने के साथ _END  \n",
       "74470                      START_ और यह खास गुब्बारा _END  \n",
       "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in data['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in data['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14030"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17540"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length_eng_sentence'] = data['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "data['length_hin_sentence'] = data['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate cli...</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "82040     ted  we still dont know who her parents are who she is   \n",
       "85038     ted                                        no keyboard   \n",
       "58018     ted                    but as far as being a performer   \n",
       "74470     ted                        and this particular balloon   \n",
       "122330    ted  and its not as hard as you think integrate cli...   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...   \n",
       "85038                       START_ कोई कुंजीपटल नहीं _END   \n",
       "58018             START_ लेकिन एक कलाकार होने के साथ _END   \n",
       "74470                      START_ और यह खास गुब्बारा _END   \n",
       "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "82040                    11                   16  \n",
       "85038                     2                    5  \n",
       "58018                     7                    8  \n",
       "74470                     4                    6  \n",
       "122330                   16                   20  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24774, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting max length of sentences as 20\n",
    "data = data[data['length_eng_sentence']<=20]\n",
    "data = data[data['length_hin_sentence']<=20]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_src = max(data['length_hin_sentence'])\n",
    "max_length_tar = max(data['length_eng_sentence'])\n",
    "max_length_src, max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14030, 17540)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For zero padding\n",
    "num_decoder_tokens += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101322</th>\n",
       "      <td>ted</td>\n",
       "      <td>“i got a surprise for you baby”</td>\n",
       "      <td>START_ “तुम्हारे लिए एक आश्चर्य है बिटिया” _END</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54143</th>\n",
       "      <td>ted</td>\n",
       "      <td>people go for walks in the woods</td>\n",
       "      <td>START_ लोग जंगलों में पदयात्रा के लिये निकल जा...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56484</th>\n",
       "      <td>ted</td>\n",
       "      <td>this was initiated in delhi prison</td>\n",
       "      <td>START_ इसकी शुरुआत हुई थी देल्ही जेल में _END</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10091</th>\n",
       "      <td>ted</td>\n",
       "      <td>punishment and examinations are seen as threats</td>\n",
       "      <td>START_ सजा और परीक्षाओं की धमकी के रूप में देख...</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119923</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this part of africa</td>\n",
       "      <td>START_ और अफ़्रीका के इस भाग में। _END</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                 english_sentence  \\\n",
       "101322    ted                  “i got a surprise for you baby”   \n",
       "54143     ted                 people go for walks in the woods   \n",
       "56484     ted               this was initiated in delhi prison   \n",
       "10091     ted  punishment and examinations are seen as threats   \n",
       "119923    ted                          and this part of africa   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "101322    START_ “तुम्हारे लिए एक आश्चर्य है बिटिया” _END   \n",
       "54143   START_ लोग जंगलों में पदयात्रा के लिये निकल जा...   \n",
       "56484       START_ इसकी शुरुआत हुई थी देल्ही जेल में _END   \n",
       "10091   START_ सजा और परीक्षाओं की धमकी के रूप में देख...   \n",
       "119923             START_ और अफ़्रीका के इस भाग में। _END   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "101322                    7                    8  \n",
       "54143                     7                   11  \n",
       "56484                     6                    9  \n",
       "10091                     7                   13  \n",
       "119923                    5                    8  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shuffle(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19819,), (4955,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = data['english_sentence'], data['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Installed\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    4209000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 300)    5262300     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 300), (None, 721200      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 300),  721200      embedding_2[0][0]                \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 17541)  5279841     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 16,193,541\n",
      "Trainable params: 16,193,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 64 # default was 128\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Installed\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Installed\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "309/309 [==============================] - 362s 1s/step - loss: 6.2616 - val_loss: 5.8945\n",
      "Epoch 2/50\n",
      "309/309 [==============================] - 360s 1s/step - loss: 5.6001 - val_loss: 5.5980\n",
      "Epoch 3/50\n",
      "309/309 [==============================] - 362s 1s/step - loss: 5.2651 - val_loss: 5.4875\n",
      "Epoch 4/50\n",
      "309/309 [==============================] - 362s 1s/step - loss: 5.0161 - val_loss: 5.3852\n",
      "Epoch 5/50\n",
      "309/309 [==============================] - 363s 1s/step - loss: 4.7979 - val_loss: 5.3269\n",
      "Epoch 6/50\n",
      "309/309 [==============================] - 363s 1s/step - loss: 4.6055 - val_loss: 5.3172\n",
      "Epoch 7/50\n",
      "309/309 [==============================] - 362s 1s/step - loss: 4.4288 - val_loss: 5.2988\n",
      "Epoch 8/50\n",
      "309/309 [==============================] - 363s 1s/step - loss: 4.2673 - val_loss: 5.2898\n",
      "Epoch 9/50\n",
      "309/309 [==============================] - 363s 1s/step - loss: 4.1178 - val_loss: 5.2989\n",
      "Epoch 10/50\n",
      "309/309 [==============================] - 363s 1s/step - loss: 3.9750 - val_loss: 5.3308\n",
      "Epoch 11/50\n",
      "309/309 [==============================] - 363s 1s/step - loss: 3.8414 - val_loss: 5.3425\n",
      "Epoch 12/50\n",
      "309/309 [==============================] - 364s 1s/step - loss: 3.7090 - val_loss: 5.3668\n",
      "Epoch 13/50\n",
      "309/309 [==============================] - 365s 1s/step - loss: 3.5822 - val_loss: 5.3969\n",
      "Epoch 14/50\n",
      "309/309 [==============================] - 370s 1s/step - loss: 3.4588 - val_loss: 5.4296\n",
      "Epoch 15/50\n",
      " 37/309 [==>...........................] - ETA: 4:58 - loss: 3.3563"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
